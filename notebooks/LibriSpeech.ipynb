{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5hvo8QWN-a9"
      },
      "source": [
        "# Installing Whisper\n",
        "\n",
        "The commands below will install the Python packages needed to use Whisper models and evaluate the transcription results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsJUxc0aRsAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f5e38fc-86ef-4998-fad3-b82e6b86079a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-1v_kwol4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-1v_kwol4\n",
            "  Resolved https://github.com/openai/whisper.git to commit 173ff7dd1d9fb1c4fddea0d41d704cfefeb8908c\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (4.66.6)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (10.5.0)\n",
            "Collecting tiktoken (from openai-whisper==20240930)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting triton>=2.0.0 (from openai-whisper==20240930)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper==20240930) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803556 sha256=d5a7fe5e5aefbc0d3c21ad7d435332093fb1fe7ea5545a275c180274c3738582\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z8_vm1p6/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: triton, tiktoken, openai-whisper\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting jiwer\n",
            "  Downloading jiwer-3.0.5-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Collecting rapidfuzz<4,>=3 (from jiwer)\n",
            "  Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading jiwer-3.0.5-py3-none-any.whl (21 kB)\n",
            "Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install git+https://github.com/openai/whisper.git\n",
        "! pip install jiwer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IMEkgyagYto"
      },
      "source": [
        "# Loading the LibriSpeech dataset\n",
        "\n",
        "The following will load the test-clean split of the LibriSpeech corpus using torchaudio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CqtR2Fi5-vP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    import tensorflow  # required in Colab to avoid protobuf compatibility issues\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import whisper\n",
        "import torchaudio\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuCCB2KYOJCE"
      },
      "outputs": [],
      "source": [
        "class LibriSpeech(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    A simple class to wrap LibriSpeech and trim/pad the audio to 30 seconds.\n",
        "    It will drop the last few seconds of a very small portion of the utterances.\n",
        "    \"\"\"\n",
        "    def __init__(self, split=\"test-clean\", device=DEVICE):\n",
        "        self.dataset = torchaudio.datasets.LIBRISPEECH(\n",
        "            root=os.path.expanduser(\"~/.cache\"),\n",
        "            url=split,\n",
        "            download=True,\n",
        "        )\n",
        "        self.device = device\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        audio, sample_rate, text, _, _, _ = self.dataset[item]\n",
        "        assert sample_rate == 16000\n",
        "        audio = whisper.pad_or_trim(audio.flatten()).to(self.device)\n",
        "        mel = whisper.log_mel_spectrogram(audio)\n",
        "\n",
        "        return (mel, text)"
      ]
    },
    {
      "source": [
        "audio, sample_rate = torchaudio.load(\"WTFB2.mp4\")\n",
        "     audio = whisper.pad_or_trim(audio.flatten()).to(DEVICE)  # Pad/trim to ~30 seconds\n",
        "     mel = whisper.log_mel_spectrogram(audio)  # Compute log-mel spectrogram"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "sAfLmpYXs02A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ljocCNuUAde"
      },
      "source": [
        "# Running inference on the dataset using a base Whisper model\n",
        "\n",
        "The following will take a few minutes to transcribe all utterances in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PokfNJtOYNu"
      },
      "outputs": [],
      "source": [
        "model = whisper.load_model(\"base.en\")\n",
        "print(\n",
        "    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
        "    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86u82ckdpk4z"
      },
      "outputs": [],
      "source": [
        "# predict without timestamps for short-form transcription\n",
        "options = whisper.DecodingOptions(language=\"en\", without_timestamps=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OWTn_KvNk59"
      },
      "outputs": [],
      "source": [
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "for mels, texts in tqdm(loader):\n",
        "    results = model.decode(mels, options)\n",
        "    hypotheses.extend([result.text for result in results])\n",
        "    references.extend(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nTyynELQ42j"
      },
      "outputs": [],
      "source": [
        "data = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPppEJRXX4ox"
      },
      "source": [
        "# Calculating the word error rate\n",
        "\n",
        "Now, we use our English normalizer implementation to standardize the transcription and calculate the WER."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl-KBDflMhrg"
      },
      "outputs": [],
      "source": [
        "import jiwer\n",
        "from whisper.normalizers import EnglishTextNormalizer\n",
        "\n",
        "normalizer = EnglishTextNormalizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-O048q4WI4o"
      },
      "outputs": [],
      "source": [
        "data[\"hypothesis_clean\"] = [normalizer(text) for text in data[\"hypothesis\"]]\n",
        "data[\"reference_clean\"] = [normalizer(text) for text in data[\"reference\"]]\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBGSITeBYPTT"
      },
      "outputs": [],
      "source": [
        "wer = jiwer.wer(list(data[\"reference_clean\"]), list(data[\"hypothesis_clean\"]))\n",
        "\n",
        "print(f\"WER: {wer * 100:.2f} %\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}